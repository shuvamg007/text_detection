{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "east_text_detection",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shuvamg007/text_detection/blob/master/east_text_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeNojPmF_yhJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CiDifWSKfWS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!wget https://www.dropbox.com/s/r2ingd0l3zt8hxs/frozen_east_text_detection.tar.gz?dl=1 && mv frozen_east_text_detection.tar.gz?dl=1 frozen_east_text_detection.tar.gz\n",
        "!tar xvzf frozen_east_text_detection.tar.gz\n",
        "!wget https://s3.amazonaws.com/tech-interview/text_detection.zip && unzip text_detection.zip\n",
        "!mkdir results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsvjkZwfBu0s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def detect(scores, geometry, threshold):\n",
        "  detections = []\n",
        "  confidences = []\n",
        "\n",
        "  height = scores.shape[2]\n",
        "  width = scores.shape[3]\n",
        "  for y in range(height):\n",
        "\n",
        "    score = scores[0][0][y]\n",
        "    x0 = geometry[0][0][y]\n",
        "    x1 = geometry[0][1][y]\n",
        "    x2 = geometry[0][2][y]\n",
        "    x3 = geometry[0][3][y]\n",
        "    angle = geometry[0][4][y]\n",
        "    \n",
        "    for x in range(width):\n",
        "\n",
        "      # continue only if score > threshold\n",
        "      if(score[x] > threshold):\n",
        "\n",
        "        offsetX = x * 4.0\n",
        "        offsetY = y * 4.0\n",
        "\n",
        "        cos = math.cos(angle[x])\n",
        "        sin = math.sin(angle[x])\n",
        "        \n",
        "        h = x0[x] + x2[x]\n",
        "        w = x1[x] + x3[x]\n",
        "\n",
        "        offsetX += (cos * x1[x]) + (sin * x2[x])\n",
        "        offsetY -= (sin * x1[x]) - (cos * x2[x])\n",
        "\n",
        "        p1 = (-(sin * h) + offsetX, -(cos * h) + offsetY)\n",
        "        p3 = (-(cos * w) + offsetX,  (sin * w) + offsetY)\n",
        "        \n",
        "        center = (0.5 * (p1[0] + p3[0]), 0.5 * (p1[1] + p3[1]))\n",
        "        \n",
        "        detections.append((center, (w, h), -(angle[x] * 180.0) / math.pi))\n",
        "        confidences.append(float(score[x]))\n",
        "\n",
        "  return [detections, confidences]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LmXr8lCjOJy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "east_model = 'frozen_east_text_detection.pb'\n",
        "\n",
        "# EAST expects input images to be of dimensions in multiple of 32\n",
        "img_width = 320\n",
        "img_height = 320\n",
        "\n",
        "res_images = []\n",
        "nms_threshold = 0.5\n",
        "confidence = 0.4\n",
        "\n",
        "# loading pre-trained model\n",
        "model = cv2.dnn.readNet(east_model)\n",
        "directory = 'text_detection/images/'\n",
        "\n",
        "layers = [\n",
        "  \"feature_fusion/Conv_7/Sigmoid\",\n",
        "  \"feature_fusion/concat_3\"\n",
        "]\n",
        "\n",
        "dataset_mean = (123.68, 116.78, 103.94)\n",
        "\n",
        "\n",
        "for file in tqdm(os.listdir(directory)):\n",
        "\n",
        "  image = cv2.imread(directory + file)\n",
        "  img_copy = image.copy()\n",
        "  (H, W) = image.shape[:2]\n",
        "\n",
        "  rW = W / float(img_width)\n",
        "  rH = H / float(img_height)\n",
        "\n",
        "  image = cv2.resize(image, (img_width, img_height))\n",
        "\n",
        "  blob = cv2.dnn.blobFromImage(image, 1.0, (img_width, img_height), dataset_mean, swapRB=True, crop=False)\n",
        "  model.setInput(blob)\n",
        "  (scores, geometry) = model.forward(layers)\n",
        "  # t, _ = model.getPerfProfile()\n",
        "  # print('Elapsed time (ms): ' + str(t * 1000.0 / cv2.getTickFrequency()))\n",
        "\n",
        "\n",
        "  detections, confidences = detect(scores, geometry, confidence)\n",
        "  indices = cv2.dnn.NMSBoxesRotated(detections, confidences, confidence, nms_threshold)\n",
        "\n",
        "  # loop over the bounding boxes\n",
        "  for i in indices:\n",
        "\n",
        "    vertices = cv2.boxPoints(detections[i[0]])\n",
        "    for j in range(4):\n",
        "      vertices[j][0] *= rW\n",
        "      vertices[j][1] *= rH\n",
        "\n",
        "    for j in range(4):\n",
        "      p1 = (vertices[j][0], vertices[j][1])\n",
        "      p2 = (vertices[(j + 1) % 4][0], vertices[(j + 1) % 4][1])\n",
        "      cv2.line(img_copy, p1, p2, (0, 255, 0), 2);\n",
        "\n",
        "  # res_images.append(img_copy)\n",
        "  cv2.imwrite('results/' + file, img_copy)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}